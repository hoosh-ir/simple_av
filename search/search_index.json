{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Simple AV project","text":"<p>simple-AV is an open-source software stack for self-driving vehicles, built on the Robot Operating System (ROS). simple-AV is written using Python, designed to facilitate autonomous vehicle simulation by directly connecting to AWSIM and replacing the Autoware framework. It was created to provide a comprehensive framework for developing and testing autonomous vehicle systems.</p>"},{"location":"#how-it-looks","title":"How it looks","text":"<p>The primary purpose of simple_AV is to ease the simulation and development of self-driving technologies by providing a robust, flexible, and easy-to-understand platform. Simple_AV includes all of the necessary functions to drive an autonomous vehicles from localization and object detection to route planning and control. While integrating AWSIM with Autoware is an effective approach, it often introduces substantial overhead. simple-AV aims to provide a more efficient solution by simplifying this process. </p> <p>This project focuses on ensuring seamless communication between AWSIM and the vehicle simulation tasks typically managed by Autoware, without the added complexity. By doing so, simple-AV offers a streamlined and effective method for autonomous vehicle simulation, handling all necessary tasks while minimizing setup and operational overhead.</p>"},{"location":"#using-awsim-with-simple-av","title":"Using AWSIM with simple-AV?","text":"<p>Simple-AV can be utilized with AWSIM for several key reasons. Firstly, simulators such as AWSIM provide a cost-effective and secure environment for testing and refining autonomous driving algorithms before they are implemented in real vehicles. Using simple-AV with a simulator allows developers to assess and adjust their algorithms without the risk of real-world accidents or damage. </p> <p>Furthermore, simulators allow developers to replicate complex driving scenarios, including challenging conditions or rare events, which are difficult to reproduce in real-world testing with high accuracy. The compatibility of simple-AV with AWSIM ensures smooth integration between the software and the simulated vehicle, enabling thorough testing and validation of autonomous driving functions. By employing a simulator, simple-AV can be rigorously tested in a variety of scenarios to confirm its robustness and reliability.</p> <p>Connection with simple-AV</p> <p>Introduction about how the connection between AWSIM and simple-AV works can be read here.</p>"},{"location":"#architecture","title":"Architecture","text":"<p>In terms of architecture, simple-AV adopts a modular approach. It is composed of several independent modules that interact through ROS2. This modular design allows users to choose and integrate various modules according to their specific needs and requirements. The software stack includes several key components, such as perception, localization, planning, and control modules. Here\u2019s a brief overview of each module:</p> <ul> <li> <p>Sensing -  Data from sensors: different sensors mounted on the autonomous vehicle such as LiDARs, Pseudo Sensors and cameras. It pre-processing received data in order to later extract relevant information about the surrounding environment through the Perception module. More details here.</p> </li> <li> <p>Pose - Acquires data from sensors like GNSS and IMU. These data then will be used in order to determine the vehicle location  by the Localization module. More details here.</p> </li> <li> <p>Perception - Uses the information from Pseudo Sensors mounted on vehicle to sense the surrounding environment. This sensor shares the information such as location, type and Bounding box of the object. Perception module then uses these information to detect other vehicles, pedestrians, lane detection, and traffic lights. More details here.</p> </li> <li> <p>Localization - performs a fusion of data from Sensing module like GNSS, IMU, and odometry sensors to estimate the vehicle's position and orientation accurately. More details here.</p> </li> <li> <p>Planning - generates a safe and feasible trajectory for the autonomous vehicle based on the information gathered from Perception and Localization. It also takes into account various factors from Map like traffic rules and road conditions. More details here.</p> </li> <li> <p>Control - executes the planned trajectory by sending commands to the vehicle's actuators, such as steering, throttle, and braking. It ensures that the vehicle follows the desired trajectory while maintaining safety and stability. More details here.</p> </li> <li> <p>Map - Simple_AV uses a .json file creted by Awsim as map. This map is a representation of the environment in which the autonomous vehicle operates. It uses data Awsim <code>waypoints</code> to generate the map (<code>*.json</code>). The map contains information about road geometries, lanes, traffic lights, rules, and other relevant features. Map serves as a crucial reference for planning and decision-making processes. More details here.</p> </li> </ul>"},{"location":"GettingStarted/AwsimScenes/","title":"Awsim Scenes","text":"<p>List of ready-to-use AWSIM scenes for the Simple AV project.</p> <ol> <li> <p>Shinjuku Scene: Nearly half of the intersections in this scene publish traffic signal messages. Additionally, the vehicle is equipped with sensors and cameras to detect other vehicles and objects.</p> </li> <li> <p>Kashiwa Scene: Coming soon.</p> </li> </ol>"},{"location":"GettingStarted/QuickStartDemo/","title":"Quick start demo","text":""},{"location":"GettingStarted/QuickStartDemo/#1-simple-av-project","title":"1. Simple AV project","text":""},{"location":"GettingStarted/QuickStartDemo/#repository-structure","title":"Repository Structure","text":"<p>This repository contains the following key directories:</p> <ul> <li>simple_av/: Contains the main nodes for the Simple_AV system, including <code>control.py</code>, <code>localization.py</code>, <code>perception.py</code> and <code>planning.py</code>.</li> <li>V2X_messages/: Includes the custom ROS message definitions that interface with the AWSIM environment.</li> <li>simple_av_msgs/: Defines internal message types used for communication between the Simple_AV nodes.</li> <li>.github/workflows/: Contains the GitHub Actions workflows for Continuous Integration (CI) and deployment of the documentation.</li> <li>docs/: The source files for the project documentation, written using MkDocs.</li> <li>mkdocs.yml: The configuration file for MkDocs, which defines the structure and theme of the documentation site.</li> </ul>"},{"location":"GettingStarted/QuickStartDemo/#getting-started","title":"Getting Started","text":"<p>To use this project, you'll need to set up a ROS 2 workspace and clone the necessary packages.</p>"},{"location":"GettingStarted/QuickStartDemo/#step-0-setup-the-environment","title":"Step 0: Setup the Environment.","text":"<p>Refer to the system setup page for detailed instructions.</p>"},{"location":"GettingStarted/QuickStartDemo/#step-1-create-a-ros-workspace","title":"Step 1: Create a ROS Workspace","text":"<p>First, create a new ROS workspace:</p> <pre><code>mkdir -p ~/ros_ws/src\n</code></pre>"},{"location":"GettingStarted/QuickStartDemo/#step-2-clone-the-repository","title":"Step 2: Clone the Repository","text":"<p>Next, clone this repository into the src directory of your workspace: <pre><code>cd ~/ros_ws/src\ngit clone https://github.com/hoosh-ir/simple_av.git\n</code></pre></p>"},{"location":"GettingStarted/QuickStartDemo/#step-3-build-the-workspace","title":"Step 3: Build the Workspace","text":"<p>After cloning the repository, build the workspace using colcon: <pre><code>cd ~/ros_ws/\ncolcon build\n</code></pre></p> <p>The workspace should look like this after running <code>colcon build</code>: <pre><code>ros_ws/\n\u251c\u2500\u2500 build/\n\u251c\u2500\u2500 install/\n\u251c\u2500\u2500 log/\n\u2514\u2500\u2500 src/\n    \u251c\u2500\u2500 docs/\n    \u251c\u2500\u2500 mkdocs.yml\n    \u251c\u2500\u2500 V2X_messages/\n    \u251c\u2500\u2500 simple_av_msgs/\n    \u2514\u2500\u2500 simple_av/\n        \u251c\u2500\u2500 package.xml\n        \u251c\u2500\u2500 resource/\n        \u251c\u2500\u2500 setup.cfg\n        \u251c\u2500\u2500 launch/\n        \u2502   \u2514\u2500\u2500 simple_av_launch.py\n        \u2514\u2500\u2500 simple_av/\n            \u251c\u2500\u2500 control.py\n            \u251c\u2500\u2500 localization.py\n            \u2514\u2500\u2500 planning.py\n</code></pre></p>"},{"location":"GettingStarted/QuickStartDemo/#step-4-source-the-workspace","title":"Step 4: Source the Workspace","text":"<p>Finally, source the workspace to make the ROS packages available: <pre><code>source ~/ros_ws/install/setup.bash\n</code></pre></p>"},{"location":"GettingStarted/QuickStartDemo/#step-5-running-the-project","title":"Step 5: Running the project","text":"<p>You can run the project by either running the launch file or by manually starting each node in sequence.</p> <p>Run the launch file: <pre><code>ros2 launch simple_av simple_av_launch.py\n</code></pre></p> <p>Or, run the nodes manually: <pre><code>ros2 run simple_av localization\nros2 run simple_av perception\nros2 run simple_av planning\nros2 run simple_av control\n</code></pre></p>"},{"location":"GettingStarted/QuickStartDemo/#2-awsim-environmet","title":"2. Awsim Environmet","text":""},{"location":"GettingStarted/QuickStartDemo/#windows","title":"Windows","text":"<p>The current Windows build version is (v6.3.1).</p> <p>You can download the build version(For Windows) to use our build version.</p> <p>(Download Kashiwa Windows Build  files (unitypackage) {.md-button .md-button--primary})</p> <p>Right now build version is only available for Windows system.</p> <p>You can use the build version in Windows and run Autoware and NetSim in WSL (Windows Subsystem for Linux). For installing the requirements for WSL, check System Setup Process.</p> <p>For better performance, we suggest users use the build version, but the Unity project version is more flexible in terms of manipulating different parameters. </p>"},{"location":"GettingStarted/QuickStartDemo/#ubuntu","title":"Ubuntu","text":"<p>Currently, the build version is not available for Ubuntu. However, you can follow the instructions in How to build section and build your Ubuntu version. </p> <p>please check the following section How to build. </p>"},{"location":"GettingStarted/QuickStartDemo/#how-to-build","title":"How to build","text":"<p>You can use the Kashiwa unity package and import it to Unity (Setup Unity Project), then follow the below instructions for building the Ubuntu version. </p> <p>Note: Old models currently exist in the exported scene to be used in the future if required. We recommend deleting these objects from the scene when you are building your project to achieve better performance at runtime.</p> <p>To build your project :</p> <ol> <li>Ensure that your changes have been saved by pressing  Ctrl + S.</li> <li>Go to File &gt; Build Settings.</li> </ol> <ol> <li>Drag and drop your scene into the box and make sure to check the highlighted checkbox.</li> <li>Press Build and choose the location to save your project.</li> </ol>"},{"location":"GettingStarted/QuickStartDemo/#maps-required-for-autoware","title":"Maps required for Autoware","text":"<p>To use Autoware in Kashiwa, Lanelet2 and point cloud (PCD) maps of Kashiwa are required. Download them from the following link.</p> <p>Kashiwa Lanelet2 and PCD</p> <p>PCD of Kashiwa is made from the 3D simulation environment to match both in simulation and Autoware. </p>"},{"location":"GettingStarted/SetupUnityProject/","title":"Setup Unity Project","text":"<p> Ensure that you are in the kashiwa branch before reading this section.</p> <p>This page is a tutorial for setting up a AWSIM Unity project.</p>"},{"location":"GettingStarted/SetupUnityProject/#environment-preparation","title":"Environment preparation","text":""},{"location":"GettingStarted/SetupUnityProject/#system-setup","title":"System setup","text":"Ubuntu 22Windows <ol> <li>Make sure your machine meets the required hardware specifications.<ul> <li>NOTE: PC requirements may vary depending on simulation contents which may change as the simulator develops</li> </ul> </li> <li>Prepare a desktop PC with Ubuntu 22.04 installed.</li> <li>Install Nvidia drivers and Vulkan Graphics API.</li> <li>Install git.</li> </ol> <ol> <li>Make sure your machine meets the required hardware specifications.<ul> <li>NOTE: PC requirements may vary depending on simulation contents which may change as the simulator develops</li> </ul> </li> <li>Prepare a desktop PC with Windows 10 or 11 (64 bit) installed.</li> <li>Install git.</li> </ol>"},{"location":"GettingStarted/SetupUnityProject/#unity-installation","title":"Unity installation","text":"<p>Info</p> <p>AWSIM's Unity version is currently 2021.1.7f1</p> <p>Follow the steps below to install Unity on your machine:</p> <ol> <li>Install UnityHub to manage Unity projects. Please go to Unity download page and download latest <code>UnityHub.AppImage</code>. </li> <li> <p>Install Unity 2021.1.7f1 via UnityHub.</p> <ul> <li>Open new terminal, navigate to directory where <code>UnityHub.AppImage</code> is download and execute the following command: <pre><code>./UnityHub.AppImage\n</code></pre></li> <li>To install Unity Editor please proceed as shown on the images below  </li> <li> <p>At this point, your Unity installation process should have started.</p> Ubuntu 22 <ul> <li>*NOTE: If the installation process has not started after clicking the green button (image above), please copy the hyperlink (by rightclicking the button and selecting <code>Copy link address</code>) and add it as a argument for Unity Hub app. An example command: <pre><code>./UnityHub.AppImage unityhub://2021.1.7f1/d91830b65d9b\n</code></pre></li> </ul> </li> <li> <p>After successful installation the version will be available under the <code>Installs</code> tab in Unity Hub. </p> </li> </ul> </li> </ol>"},{"location":"GettingStarted/SetupUnityProject/#open-awsim-project","title":"Open AWSIM project","text":"<p>To open the Unity AWSIM project in Unity Editor: 1. Make sure you have the AWSIM repository cloned     <pre><code>git clone https://github.com/tlab-wide/V2X_E2E_Simulator.git\n</code></pre> 2. (Fore version 6.3.1 we have some issues so) remove this folder: V2X_E2E_Simulator/Assets/KashiwaPackage/Script</p> <ol> <li> <p>Launch UnityHub.     <pre><code>./UnityHub.AppImage\n</code></pre></p> </li> <li> <p>Open the project in UnityHub</p> <ul> <li> <p>Click the <code>Open</code> button </p> </li> <li> <p>Navigate the directory where the AWSIM repository was cloned to </p> </li> <li> <p>The project should be added to <code>Projects</code> tab in Unity Hub. To launch the project in Unity Editor simply click the <code>AWSIM</code> item </p> </li> <li> <p>The project is now ready to use </p> </li> </ul> </li> </ol> <p>Warning</p> <p>If you get the safe mode dialog when starting UnityEditor, you may need to install openssl.</p> <ol> <li>download libssl <code>$ wget http://security.ubuntu.com/ubuntu/pool/main/o/openssl1.0/libssl1.0.0_1.0.2n-1ubuntu5.13_amd64.deb</code></li> <li>install <code>sudo dpkg -i libssl1.0.0_1.0.2n-1ubuntu5.13_amd64.deb</code></li> </ol>"},{"location":"GettingStarted/SetupUnityProject/#import-external-packages","title":"Import external packages","text":"<p>To properly run and use AWSIM project in Unity it is required to download map package which is not included in the repository.</p> <ol> <li> <p>Download and import <code>Japan_Tokyo_Nishishinjuku.unitypackage</code></p> <p>Download Nishishinjuku Scence (unitypackage)</p> </li> <li> <p>In Unity Editor, from the menu bar at the top, select <code>Assets -&gt; Import Package -&gt; Custom Package...</code> and navigate the <code>Japan_Tokyo_Nishishinjuku.unitypackage</code> file.  </p> </li> <li> <p><code>Nishishinjuku</code> package has been successfully imported under <code>Assets/AWSIM/Externals/</code>directory. </p> </li> <li> <p>Download Kashiwa package and follow steps 1 ~ 3.     Download Kashiwa Scence (unitypackage 6.3)</p> </li> </ol> <p>Info</p> <p>The Externals directory is added to the <code>.gitignore</code> because the map has a large file size and should not be directly uploaded to the repository.</p>"},{"location":"GettingStarted/SetupUnityProject/#run-the-demo-in-editor","title":"Run the demo in Editor","text":"<p>The following steps describe how to run the demo in Unity Editor:</p> <ol> <li>Open the <code>AutowareSimulation.unity</code> scene placed under <code>Assets/AWSIM/Scenes/Main</code> directory</li> <li> <p>Run the simulation by clicking <code>Play</code> button placed at the top section of Editor. </p> </li> <li> <p>To Use kashiwa scene check <code>Assets/KashiwaPackage/Scenes/</code> directroy  </p> </li> </ol>"},{"location":"GettingStarted/SetupUnityProject/#bug-fix","title":"Bug fix","text":"<p>It is probable that you required to check the that the read/write be enable as you can see in the picture</p> <p>\"It is likely that you need to check the <code>\\Assets\\AWSIM\\Models\\Sensors\\Velodyne VLP-16</code> VLP-16.fbx file to ensure that the read/write option is enabled, as shown in the picture.\"</p> <p></p>"},{"location":"ProjectGuide/GitBranch/","title":"Git branch","text":"<p>The document presents the rules of branching adopted in the V2X-simulator and simple-av development process.</p>"},{"location":"ProjectGuide/GitBranch/#branches","title":"Branches","text":"branch explain main Stable branch. Contains all the latest releases. feature/*** Feature implementation branch created from <code>kashiwa</code>. After implementation, it is merged into <code>kashiwa</code>. fix/*** bug fix implementation branch created from <code>kashiwa</code>. After implementation, it is merged into <code>kashiwa</code>. doc/*** doc branch created from <code>kashiwa</code>. After implementation, it is merged into <code>kashiwa</code>. gh-pages Documentation hosted on GitHub pages."},{"location":"Simple-AV/Awsim%20msg/","title":"Build AWSIM Messages","text":""},{"location":"Simple-AV/Awsim%20msg/#awsim-topics","title":"Awsim Topics","text":"<p>AWSIM uses topics to send and receive data. It publishes data like position, lidar sensing, vehicle status, and even user-defined data using ROS topics. It also subscribes to topics containing control command data to move the vehicle.</p> <p>A few of these topics, such as <code>gnss/sensing/pose</code> which determines the exact position of the vehicle, use messages that are already defined in ROS. However, other topics use custom messages that need to be defined to read and use them.</p> <p>Awsim ROS2 topic lists Shows the full information on these topics and their relation. These topics can be shown on your system using the following process.</p> <p>Run Awsim and WSL</p> <p>First, run the Awsim or the built scene of it. You can use this scene. Secondly, Run the WSL and source the ROS2 init using the command below:</p> <pre><code>source /opt/ros/humble/setup.bash\n</code></pre> <p>After sourcing the ROS2 you can get a topic list and see all of the topics that are being published and subscribed by AWSIM. </p> <p></p> <p>Topics</p> <p>The list of Topics above shows all the topics related to Awsim. But, which one of them are being published by Awsim and which ones do the Awsim subscives to. Generally Awsim publishes all of the topics instead the Control command ones. You can see the full relation and published/subscribed topics using the command below.</p> <pre><code>rqt_graph\n</code></pre> <p>After running the command above a new window will appear. In this window unchek the `leaf topics'. As you can see all of the control topics are the ones that Awsim Subscribes to in order to control the vehicle. So by filling and publishing into these topics we can take control of the vehicle displayed in Awsim.</p> <p></p> <p>Now, if you uncheck the <code>dead sinks</code>, rqt-graph shows the topics that Awsim publishes.</p>"},{"location":"Simple-AV/Awsim%20msg/#_1","title":"Add Messages","text":""},{"location":"Simple-AV/Awsim%20msg/#simple-av-messages","title":"Simple AV messages","text":"<p>To communicate with AWSIM and launch the Simple AV project, we need to build certain message types. First, we need to build the messages used by AWSIM to send and receive data from the scene. Then, we must build the internal messages for Simple AV. These messages handle communication between the Simple AV nodes, as shown in the Simple AV architecture.</p> <p>In the Simple AV GitHub repository, you will find two packages: V2X_messages and simple_av_msgs. After cloning this repository into the src folder of your workspace, build the entire project along with the messages using the colcon command. You can follow the steps below to create a ROS workspace and build the project. Alternatively, you can visit the getting started guide or check the repository's README for full installation instructions.</p>"},{"location":"Simple-AV/Awsim%20msg/#step-1-create-a-ros-workspace","title":"Step 1: Create a ROS Workspace","text":"<p>First, create a new ROS workspace: <pre><code>mkdir -p ~/ros_ws/src\n</code></pre></p>"},{"location":"Simple-AV/Awsim%20msg/#step-2-clone-the-repository","title":"Step 2: Clone the Repository","text":"<p>Next, clone this repository into the src directory of your workspace: <pre><code>cd ~/ros_ws/src\ngit clone https://github.com/hoosh-ir/simple_av.git\n</code></pre></p>"},{"location":"Simple-AV/Awsim%20msg/#step-3-build-the-workspace","title":"Step 3: Build the Workspace","text":"<p>After cloning the repository, build the workspace using colcon: <pre><code>cd ~/ros_ws/\ncolcon build\n</code></pre></p> <p>The workspace should look like this after running <code>colcon build</code>: <pre><code>ros_ws/\n\u251c\u2500\u2500 build/\n\u251c\u2500\u2500 install/\n\u251c\u2500\u2500 log/\n\u2514\u2500\u2500 src/\n    \u251c\u2500\u2500 docs/\n    \u251c\u2500\u2500 mkdocs.yml\n    \u251c\u2500\u2500 V2X_messages/\n    \u251c\u2500\u2500 simple_av_msgs/\n    \u2514\u2500\u2500 simple_av/\n        \u251c\u2500\u2500 package.xml\n        \u251c\u2500\u2500 resource/\n        \u251c\u2500\u2500 setup.cfg\n        \u251c\u2500\u2500 launch/\n        \u2502   \u2514\u2500\u2500 simple_av_launch.py\n        \u2514\u2500\u2500 simple_av/\n            \u251c\u2500\u2500 control.py\n            \u251c\u2500\u2500 localization.py\n            \u2514\u2500\u2500 planning.py\n</code></pre></p>"},{"location":"Simple-AV/JsonMap/","title":"Map","text":"<p>Simple-AV uses the simplest form of map. This map which is a Json file, contains some crusial information about the environment which the autonomous vehicle operates in. Below you can see the format designed for this map file. The Localization module uses this format to read the input map file. Also, the Planning module uses this map for path planning purposes.</p> <pre><code>{\n    \"LaneLetsArray\": [\n        {\n            \"name\":\n            \"waypoints\": [\n                { \"x\":  \"y\": \"z\": },\n                { \"x\":  \"y\": \"z\": }\n            ],\n            \"prevLanes\": [],\n            \"nextLanes\": [],\n            \"trafficlightsWayIDs\": [],\n            \"stopLinePoseP1\": [],\n            \"stopLinePoseP2\": [],\n            \"densed_waypoints\": [\n                { \"x\":  \"y\": \"z\": },\n                { \"x\":  \"y\": \"z\": }\n            ],\n            \"adjacentLanes\": []\n        },\n        {\n            # data of another lane\n        }\n    ]\n}\n</code></pre>"},{"location":"Simple-AV/JsonMap/#json-file-layout-and-architecture","title":"JSON File Layout and Architecture","text":"<p>Root Element:</p> <ul> <li>LaneLetsArray: An array containing multiple lanelet objects.</li> </ul> <p>Lanelet Object Structure:</p> <ul> <li>name: The name of the lanelet (string).</li> <li>waypoints: An array of waypoint objects, each containing coordinates (x, y, z).<ul> <li>x: The x-coordinate of the waypoint (float).</li> <li>y: The y-coordinate of the waypoint (float).</li> <li>z: The z-coordinate of the waypoint (float).</li> </ul> </li> <li>prevLanes: An array of strings representing the names of previous lanelets.</li> <li>nextLanes: An array of strings representing the names of next lanelets.</li> <li>adjacentLanes: An array of strings representing the names of adjacent lanelets of the this lane.</li> <li>trafficlightsWayIDs: An array of integers representing traffic light way IDs.</li> <li>stopLinePoseP1: An array of three floats representing the first point of the stop line pose (x, y, z).</li> <li>stopLinePoseP2: An array of three floats representing the second point of the stop line pose (x, y, z).</li> <li>densed_waypoints: An array of waypoint objects, which is more densed. The distance between each two consecutive points can be determined. For examle, the distance can be set to 2.0 meters.<ul> <li>x: The x-coordinate of the waypoint (float).</li> <li>y: The y-coordinate of the waypoint (float).</li> <li>z: The z-coordinate of the waypoint (float).</li> </ul> </li> </ul>"},{"location":"Simple-AV/JsonMap/#how-to-generate-this-map-from-awsim","title":"How to generate this map from Awsim.","text":"<p>An important consideration is that this map is generated using AWSIM. AWSIM itself uses PCD and Lanelet map files to create waypoints containing information about lanes. To simplify the process for simple_AV, we eliminate the use of Lanelet and PCD map files, utilizing only the AWSIM waypoint. The JSON file mentioned is created and populated in AWSIM using a C# code. Then we use a python code to update the map by adding the adjacent lanes and densed waypoints to each lane. Map making repository</p>"},{"location":"Simple-AV/Modules/Control/","title":"Control Module","text":"<p>The Control Module in simple-AV is responsible for executing the planned trajectory by sending commands to the vehicle's actuators, such as steering, acceleration, and gear. It ensures that the vehicle follows the desired trajectory while maintaining safety and stability. The control process involves controlling the vehicle's longitudinal speed, steering angle, and gear.</p>"},{"location":"Simple-AV/Modules/Control/#key-algorithms-and-components","title":"Key Algorithms and Components","text":"<ol> <li> <p>PID Controller for Longitudinal Speed Control:</p> <ul> <li>The PID (Proportional-Integral-Derivative) controller adjusts the vehicle's acceleration to maintain the target speed.</li> <li>The controller calculates the error between the observed speed and the target speed, and computes the required acceleration to minimize this error.</li> </ul> </li> <li> <p>Pure Pursuit Algorithm for Steering Control:</p> <ul> <li>The Pure Pursuit algorithm is used to calculate the required steering angle to follow the path accurately.</li> <li>It computes the curvature that will move the vehicle from its current position to a goal position, known as the look-ahead point.</li> </ul> </li> <li> <p>Gear Control:</p> <ul> <li>The module controls the vehicle's gear, switching between 'Drive' and 'Park' based on the current status of the vehicle.</li> </ul> </li> </ol>"},{"location":"Simple-AV/Modules/Control/#inputs-to-the-control-module","title":"Inputs to the Control Module","text":"<p>The Control Module receives data from various sources to perform its tasks:</p> <ul> <li>Look-Ahead Point: Provided by the Planning Module via the <code>simple_av/planning/lookahead_point</code> topic.</li> <li>Current Vehicle State: Includes the vehicle's current speed, orientation, and position from topics such as <code>/sensing/gnss/pose</code>, <code>/awsim/ground_truth/vehicle/pose</code>, and <code>/vehicle/status/velocity_status</code>.</li> <li>Status and Speed Limit: Instructions from the Planning Module indicating the current maneuver (e.g., cruise, decelerate, turn).</li> </ul>"},{"location":"Simple-AV/Modules/Control/#outputs-from-the-control-module","title":"Outputs from the Control Module","text":"<p>The Control Module publishes commands to the vehicle's actuators to control its motion. These commands include:</p> <ul> <li>Steering Command: The angle at which the vehicle should steer to follow the path.</li> <li>Acceleration Command: The acceleration needed to reach and maintain the target speed.</li> <li>Gear Command: The gear state of the vehicle, such as 'Drive' or 'Park'.</li> </ul>"},{"location":"Simple-AV/Modules/Control/#topics","title":"Topics","text":"<ul> <li>Input Topic: <code>simple_av/planning/lookahead_point</code></li> <li> <p>Message Format:</p> <ul> <li><code>geometry_msgs.msg/Point look_ahead_point</code></li> <li><code>geometry_msgs.msg/Point stop_point</code></li> <li><code>string status</code></li> <li><code>float speed_limit</code></li> </ul> </li> <li> <p>Output Topics: </p> </li> <li><code>AckermannControlCommand</code> on <code>/control/command/control_cmd</code><ul> <li>Message Format:</li> <li><code>AckermannLateralCommand lateral</code></li> <li><code>LongitudinalCommand longitudinal</code></li> </ul> </li> <li><code>GearCommand</code> on <code>/control/command/gear_cmd</code><ul> <li>Message Format:</li> <li><code>GearCommand</code></li> </ul> </li> </ul>"},{"location":"Simple-AV/Modules/Control/#control-strategy","title":"Control Strategy","text":"<p>The Control Module follows a feedback control strategy, constantly adjusting its commands based on real-time data from the vehicle and the Planning Module. This ensures the vehicle adheres to the planned path while dynamically responding to changes in the environment and the vehicle's state.</p>"},{"location":"Simple-AV/Modules/Control/#pid-controller","title":"PID Controller","text":"<p>The PID controller in the Control Module is used to maintain the target speed by controlling the vehicle's acceleration. It adjusts the acceleration based on the error between the observed and target speeds, using proportional, integral, and derivative gains.</p>"},{"location":"Simple-AV/Modules/Control/#pure-pursuit-algorithm","title":"Pure Pursuit Algorithm","text":"<p>The Pure Pursuit algorithm computes the steering angle required to follow the path. It calculates the curvature to move the vehicle from its current position to the look-ahead point.</p>"},{"location":"Simple-AV/Modules/Control/#summary","title":"Summary","text":"<p>The Control Module is vital for translating the planned trajectories into actual vehicle movements. By leveraging the PID controller for speed control and the Pure Pursuit algorithm for steering control, along with managing the gear state, it ensures precise and safe navigation of the autonomous vehicle.</p>"},{"location":"Simple-AV/Modules/Localization/","title":"Localization Module","text":"<p>The Localization module in simple-AV is designed to accurately determine the position and orientation of the autonomous vehicle within its environment using GNSS/pose data. This module is crucial for ensuring that the vehicle can navigate safely and effectively, as it provides the foundational data needed for all subsequent decision-making processes, such as perception, planning, and control.</p>"},{"location":"Simple-AV/Modules/Localization/#overview","title":"Overview","text":"<p>Localization is achieved by utilizing GNSS/pose data to determine the vehicle's position within a predefined map. This map is stored in a JSON file, which includes detailed information about the city's lanelets, their connections, waypoints, and traffic light locations. The Localization module processes this data to identify the vehicle's current lane and the closest waypoint within that lane.</p>"},{"location":"Simple-AV/Modules/Localization/#key-components","title":"Key Components","text":"<ul> <li> <p>GNSS/Pose Data: Provides the vehicle's current coordinates (x, y, z). This data is used to determine the vehicle's position relative to the predefined map.</p> </li> <li> <p>JSON Map: Contains all lanelets of the city, including their next, previous, and adjacent lanes. Each lanelet consists of waypoints and traffic light information, providing a comprehensive representation of the driving environment.</p> </li> </ul>"},{"location":"Simple-AV/Modules/Localization/#functionality","title":"Functionality","text":"<p>The Localization module performs several critical functions to ensure accurate and reliable vehicle positioning:</p> <ol> <li> <p>Global Localization: At the beginning of the process, the global localization component compares the GNSS/pose data to all the waypoints in each lanelet. This step determines the currently occupied lane and is computationally intensive, so it is only performed initially to establish the vehicle's starting position.</p> </li> <li> <p>Local Localization: Once the vehicle's initial position is determined, the local localization component takes over. It creates a search area based on the current lane to limit the computational load. This localized search ensures that the process is efficient and can run in real-time without excessive computational demands.</p> </li> <li> <p>Lane and Waypoint Determination: The module continuously checks if the vehicle is within the current lane and identifies which waypoint is closest to the vehicle. This helps in maintaining accurate localization and provides essential data for navigation.</p> </li> <li> <p>Topic Creation: The Localization module creates a topic named <code>simple_av/localization/location</code>. The messages in this topic include:</p> <ul> <li>Current lane</li> <li>Closest waypoint</li> <li>Distance to the closest waypoint</li> </ul> </li> </ol>"},{"location":"Simple-AV/Modules/Localization/#integration","title":"Integration","text":"<p>The Localization module is tightly integrated with planning components of the simple-AV software stack:</p> <ul> <li>Planning Module: Relies on precise localization to generate safe and feasible trajectories for the vehicle to follow.</li> </ul>"},{"location":"Simple-AV/Modules/Localization/#advantages","title":"Advantages","text":"<ul> <li> <p>High Accuracy: By utilizing GNSS/pose data and a detailed map, the Localization module provides a highly accurate estimate of the vehicle's position and orientation.</p> </li> <li> <p>Efficiency: The two-tiered approach of global and local localization ensures that the system is both accurate and computationally efficient.</p> </li> <li> <p>Real-Time Operation: Capable of processing data and updating the vehicle's pose in real-time, essential for dynamic and responsive autonomous driving.</p> </li> <li> <p>Seamless Integration: Works seamlessly with other modules in the simple-AV stack, facilitating comprehensive and efficient autonomous vehicle operation.</p> </li> </ul>"},{"location":"Simple-AV/Modules/Perception/","title":"Perception Module","text":"<p>The Perception Module in simple-AV is responsible for interpreting data from various sensors to understand the vehicle's surroundings. This module processes information from sensors to detect and identify objects, obstacles, and road features, providing critical inputs for navigation and decision-making.</p>"},{"location":"Simple-AV/Modules/Perception/#key-functions","title":"Key Functions","text":"<ol> <li> <p>Object Detection:</p> <ul> <li>The module identifies and classifies objects in the environment, such as other vehicles, pedestrians, traffic signs, and lane markings.</li> <li>It utilizes data from sensors like LiDARs and cameras to detect objects and their spatial properties.</li> </ul> </li> <li> <p>Traffic Light Detection:</p> <ul> <li>The module detects traffic lights and their statuses (e.g., red, green, amber) to manage the vehicle\u2019s response to traffic signals.</li> <li>It processes visual data from cameras to determine the state of traffic lights at intersections.</li> </ul> </li> <li> <p>Sensor Data Integration:</p> <ul> <li>The Perception Module integrates data from multiple topics, such as v2x and v2i, to create a comprehensive representation of the environment.</li> </ul> </li> </ol>"},{"location":"Simple-AV/Modules/Planning/","title":"Planning Module","text":"<p>The Planning module in simple-AV is responsible for generating safe and feasible trajectories for the autonomous vehicle. This module utilizes data from the Localization and Perception modules to plan a path that ensures the vehicle navigates effectively while adhering to traffic rules and road conditions. The planned trajectory is then executed by the Control module to move the vehicle along the desired path.</p>"},{"location":"Simple-AV/Modules/Planning/#overview","title":"Overview","text":"<p>The Planning module processes information about the vehicle's current position, detected objects, and the environment to generate a trajectory that the vehicle can follow. This involves several steps, including path planning, behavior planning, and motion planning. Each of these steps ensures that the vehicle's trajectory is safe, smooth, and efficient.</p>"},{"location":"Simple-AV/Modules/Planning/#key-components","title":"Key Components","text":"<ul> <li>Localization Data: Provides the current position and orientation of the vehicle, which is essential for accurate path planning.</li> <li>Perception Data: Provides information about surrounding objects, road conditions, and traffic signals. This data is critical for avoiding obstacles and adhering to traffic rules.</li> <li>Map Data: Includes information about the road network, lanelets, traffic lights, and waypoints. This data is used to ensure that the planned path is feasible and adheres to road rules.</li> </ul>"},{"location":"Simple-AV/Modules/Planning/#functionality","title":"Functionality","text":"<p>The Planning module performs several critical functions to ensure that the vehicle follows a safe and efficient path. The process of path planning consists of three main parts:</p>"},{"location":"Simple-AV/Modules/Planning/#mission-planning","title":"Mission Planning","text":"<p>The mission planning phase determines the path that the vehicle should take from the source point (obtained from the Localization module) to the destination lane (specified in the code). This part uses a Breadth-First Search (BFS) algorithm for routing, covering lane changes if needed. Mission planning only occurs once at the beginning of the process and saves all of the lanes and points from source to destination in a class variable to be used later. Other parts of the Planning module then use this <code>path</code> and <code>path_as_lanes</code> created by mission planning to perform their tasks.</p>"},{"location":"Simple-AV/Modules/Planning/#local-planning","title":"Local Planning","text":"<p>The local planning task uses the path of waypoints created in mission planning to determine the look-ahead point based on the defined look-ahead distance. This point is then published to be used in the Control module. </p>"},{"location":"Simple-AV/Modules/Planning/#behavioral-planning","title":"Behavioral Planning","text":"<p>Behavioral planning determines the high-level maneuvers the vehicle should perform, such as lane changes, turns, and stops at traffic lights. This step ensures that the vehicle behaves in a manner that is safe and predictable.</p>"},{"location":"Simple-AV/Modules/Planning/#handling-stops","title":"Handling Stops","text":"<p>Since the vehicle needs to stop at certain points along the path, such as at the destination and at traffic light stop lines, the Planning module also handles these stopping points. Similar to the look-ahead distance, a stop distance (which is larger than the look-ahead distance) is defined. The stop distance acts as a look-ahead for points where the vehicle should stop.</p>"},{"location":"Simple-AV/Modules/Planning/#topic-creation","title":"Topic Creation","text":"<p>The Planning module creates a topic named <code>simple_av/planning/lookahead_point</code>. The messages in this topic include:</p> <ul> <li>Look-Ahead Point: The next waypoint the vehicle should aim for.</li> <li>Stop Point: The point where the vehicle should stop.</li> <li>Status: A string indicating the vehicle's current action, such as:<ul> <li><code>Cruise</code>: The vehicle should continue moving.</li> <li><code>Decelerate</code>: The vehicle should slow down.</li> <li><code>Turn</code>: The vehicle should make a turn.</li> <li><code>red_stop</code> or <code>amber_stop</code>: The traffic light is red or amber, and the vehicle must slow down and stop at the stop point.</li> <li><code>green_cruise</code>: The traffic light is green, and the vehicle should continue moving.</li> <li><code>Park</code>: The vehicle must stop completely.</li> </ul> </li> <li>Speed Limit: The speed limit for the current segment of the path.</li> </ul> <p>Look-ahead point and stop points are of type <code>geometry_msgs.msg/Point</code>.</p>"},{"location":"Simple-AV/Modules/Planning/#integration","title":"Integration","text":"<p>The Planning module is designed to integrate seamlessly with other modules in the simple-AV architecture. It receives input from the Localization and Perception modules and sends its output to the Control module. This integration ensures that the vehicle can navigate effectively in a dynamic environment while maintaining safety and efficiency.</p> <p>By utilizing data from multiple sources and employing sophisticated planning algorithms, the Planning module plays a crucial role in the autonomous operation of the vehicle, ensuring that it can navigate complex environments and respond to changing conditions in real-time.</p>"},{"location":"Simple-AV/SystemSetup/","title":"Environment Setup for simple-AV","text":"<p>This guide will walk you through the steps to set up an environment in Windows 10 for launching the simple-AV, including the installation of AWSIM, ROS2 Humble, and WSL.</p> <p>To develop and run simple-AV, it is essential to establish communication between AWSIM and ROS2. For this project, AWSIM is installed on Windows 10, while Ubuntu 22.04 is installed on WSL (Windows Subsystem for Linux) within Windows 10. ROS2 is then installed on Ubuntu 22.04 within WSL.</p> <p>Given the crucial need for seamless communication between simple-AV and AWSIM, we ensure proper setup for the exchange of ROS topics. This involves configuring the network settings to enable ROS topics to be sent and received correctly between the Windows 10 environment and the ROS2 installation on WSL.</p>"},{"location":"Simple-AV/SystemSetup/#system-setup-process","title":"System Setup process","text":"<p>More specifically, this document goes through the installation process of</p> <ul> <li>Installing WSL2 on Windows 10</li> <li>Installing ROS2 Humble on Ubuntu 22.04 on WSL2</li> <li>Setting up AWSIM on Window 10</li> <li>Setting up Awsim and WSL2 connection</li> </ul> <p>For running AWSIM on Windows and get the topics in WSL, you don\u2019t need to actually install ROS2 for Windows.</p> <p>By following this guide, you will create a development environment that supports efficient communication between AWSIM and ROS2, enabling the successful deployment of the simple-AV ROS node.</p>"},{"location":"Simple-AV/SystemSetup/#setting-up-awsim-on-window","title":"Setting up AWSIM on Window","text":"<p>You can use the provided scenes in Awsim Scenes for testing and working on the Simple AV project. Additionally, you can install AWSIM using the Quick start demo provided in the AWSIM documentation. This will give you access to Unity and AWSIM, allowing you to modify scenes, messages, topics, and objects in the simulator.</p> <p></p> <p>The picture below shows the Awsim environment after running the AWSIM.exe file</p> <p></p>"},{"location":"Simple-AV/SystemSetup/#how-to-build-scene-using-awsim","title":"How to build scene using Awsim","text":"<p>//TODO: Kashi</p>"},{"location":"Simple-AV/SystemSetup/#setting-up-awsim-and-wsl2-connection","title":"Setting up Awsim and WSL2 connection","text":"<p>Before running AWSIM, you need to make a few changes to your Windows 10 environment to make sure that the messages and topic correctly transfer to your WSL2 environment.</p>"},{"location":"Simple-AV/SystemSetup/#step-1-set-environment-variables","title":"Step 1: Set environment variables","text":"<p>By default, ROS2 on Windows uses the FastDDS middleware. You need to change that to CycloneDDS for AWSIM messages to be able to transfer to your WSL2 environment.</p> <p>Open the system environment variables panel on Windows. Click on Environment Variables.</p> <p></p> <p>In the <code>System variables section</code> create two new variables:</p> <ol> <li>RMW_IMPLEMENTATION: rmw_cyclonedds_cpp</li> <li>ROS_LOCALHOST_ONLY: 0</li> </ol> <p></p> <p>Finally, reboot your system.</p>"},{"location":"Simple-AV/SystemSetup/#step-2-disable-the-windows-lso-large-send-offload","title":"Step 2: Disable the Windows LSO (large send offload)","text":"<p>Explanation of Large Send Offload (LSO): LSO is a feature that helps improve network performance by offloading packet segmentation tasks from the CPU to the network adapter hardware. However, in some scenarios, LSO can cause network issues, especially with virtual network adapters or certain types of network traffic. Disabling LSO can help resolve such issues.</p> <p>Why Disable LSO on WSL Adapter?: Disabling LSO on the WSL virtual Ethernet adapter might be necessary if you're experiencing network performance issues or connectivity problems with applications running in WSL. By disabling LSO, you force the CPU to handle packet segmentation, which can sometimes result in more stable network behavior in virtualized environments.</p> <p>1- open Windows Powershell as administrator. </p> <p>2- Run the command below to Identify the network adapters.</p> <p><pre><code>Get-NetAdapter -IncludeHidden\n</code></pre> This command used to retrieve information about the network adapters on a Windows system, including those that are hidden. By using this command, you can see all network adapters on the system, including those that are not currently in use or visible in the standard network settings interface. This can be useful for troubleshooting network issues or for getting a complete inventory of all network interfaces on a system.</p> <p>In this Step the network adapters are something like below. </p> <p>3- Run the command below to Disable Large Send Offload (LSO).</p> <p><pre><code>Disable-NetAdapterLso -IncludeHidden -Name \"vEthernet (WSL)\"\n</code></pre> This command disables the Large Send Offload (LSO) feature on the specified network adapter, including hidden ones. LSO offloads the task of segmenting large TCP/IP packets to the network adapter hardware.</p> <p>4- Run the command below to Check the advanced properties.</p> <pre><code>Get-NetAdapterAdvancedProperty -IncludeHidden -Name \"vEthernet (WSL)\"\n</code></pre> <p>This command retrieves advanced properties and settings of the specified network adapter, including hidden ones.</p> <p>5- Run the command below to Restart the WSL adapter.</p> <pre><code>Restart-NetAdapter -IncludeHidden -Name \"vEthernet (WSL)\"\n</code></pre> <p>This command restarts the specified network adapter, including hidden ones. To apply and solidify changes made to the network adapter settings, such as disabling LSO. Restarting the adapter ensures that all configuration changes take effect and the adapter operates with the updated settings.</p> <p>After running the 4 commands above, once again run the <code>Get-NetAdapterAdvancedProperty -IncludeHidden -Name \"vEthernet (WSL)\"</code> command. As is shown in the picture below, the Lso should be Off and the RegistryValue must be {0}</p> <p></p> <p>Once again reboot your system.</p>"},{"location":"Simple-AV/SystemSetup/#testing","title":"Testing","text":"<p>1. Run Awsim</p> <p>After completing the 4 steps mentioned in System setup process, run one of the scenes provided in Awsim scenes. </p> <p>2. Run WSL2</p> <p>Now, run the WSL and source the ROS2 init using the command below:</p> <pre><code>source /opt/ros/humble/setup.bash\n</code></pre> <p>After sourcing the ROS2 you can get a topic list and see the all the topics that are being published and subscribed by AWSIM. </p> <p></p> <p>This means we have successfully setup our system and create a communication between Awsim on Windows and Ros2 on WSL. However, currently we are unable to access all of the topics and we must define message types of the topics. Please refer to Building Messages page to see the full documentation.</p>"}]}